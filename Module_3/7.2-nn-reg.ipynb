{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVOtlo1QnMwz"
   },
   "source": [
    "# TensorFlow and TensorBoard with Regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9BDVGNbbEaX"
   },
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QrFX6SUnUwC"
   },
   "source": [
    "The purpose of this lab is threefold.  \n",
    "\n",
    "1.   to review using `TensorFlow` and `TensorBoard` for modeling and evaluation with neural networks\n",
    "2.   to review using data science pipelines and cross-validation with neural networks\n",
    "3.   to review using `TensorFlow` for neural network regularization\n",
    "\n",
    "We'll be continuting our investigation of the canonical [Titanic Data Set](https://www.kaggle.com/competitions/titanic/overview) that we began [previously](https://github.com/learn-co-curriculum/enterprise-paired-nn-eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unefoXqXYRxD"
   },
   "source": [
    "## The Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDT8p0nBZjVX"
   },
   "source": [
    "### The Titanic and it's data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2UPXuXmZxj5"
   },
   "source": [
    "\n",
    "\n",
    "RMS Titanic was a British passenger liner built by Harland and Wolf and operated by the White Star Line. It sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton, England to New York City, USA.\n",
    "\n",
    "Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making the sinking one of modern history's deadliest peacetime commercial marine disasters. \n",
    "\n",
    "Though there were about 2,224 passengers and crew members, we are given data of about 1,300 passengers. Out of these 1,300 passengers details, about 900 data is used for training purpose and remaining 400 is used for test purpose. The test data has had the survived column removed and we'll use neural networks to predict whether the passengers in the test data survived or not. Both training and test data are not perfectly clean as we'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TejSm5Jcyh7o"
   },
   "source": [
    "Below is a picture of the Titanic Museum in Belfast, Northern Ireland."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "n_o3ZveKwDxR",
    "outputId": "7fa3b282-95e9-48cd-80b1-709eafc01f37",
    "ExecuteTime": {
     "end_time": "2024-09-27T15:58:16.490428Z",
     "start_time": "2024-09-27T15:58:16.474780Z"
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/c/c0/Titanic_Belfast_HDR.jpg\", width=400, height=400)"
   ],
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c0/Titanic_Belfast_HDR.jpg\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO5Qrri1Zz9b"
   },
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJTNWdE1ZmI2"
   },
   "source": [
    "*   *Survival* : 0 = No, 1 = Yes\n",
    "*   *Pclass* : A proxy for socio-economic status (SES)\n",
    "  *   1st = Upper\n",
    "  *   2nd = Middle\n",
    "  *   3rd = Lower\n",
    "*   *sibsp* : The number of siblings / spouses aboard the Titanic\n",
    "  *   Sibling = brother, sister, stepbrother, stepsister\n",
    "  *   Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "*   *parch* : The # of parents / children aboard the Titanic\n",
    "  *   Parent = mother, father\n",
    "  *   Child = daughter, son, stepdaughter, stepson\n",
    "  *   Some children travelled only with a nanny, therefore *parch*=0 for them.\n",
    "*   *Ticket* : Ticket number\n",
    "*   *Fare* : Passenger fare (British pounds)\n",
    "*   *Cabin* : Cabin number embarked\n",
    "*   *Embarked* : Port of Embarkation\n",
    "  *   C = Cherbourg (now Cherbourg-en-Cotentin), France\n",
    "  *   Q = Queenstown (now Cobh), Ireland\n",
    "  *   S = Southampton, England\n",
    "*   *Name*, *Sex*, *Age* (years) are all self-explanatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1adtHjJCE5sd"
   },
   "source": [
    "## Libraries and the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zoz_n8VnFdxB"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lS0qLxZmnLHw",
    "outputId": "f60ce5f2-bfd4-4f5e-e6a9-e25f1d3e4e9b",
    "ExecuteTime": {
     "end_time": "2024-09-27T15:59:33.900695Z",
     "start_time": "2024-09-27T15:59:29.609564Z"
    }
   },
   "source": [
    "# Load the germane libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from pandas._libs.tslibs import timestamps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import models, Input\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.api.layers import Dense, Dropout\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.losses import binary_crossentropy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.regularizers import l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Load the TensorBoard notebook extension and related libraries\n",
    "%load_ext tensorboard\n",
    "import datetime"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-ljPxHFaf3_"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NXuO8yi1EjaX",
    "ExecuteTime": {
     "end_time": "2024-09-27T15:59:45.756263Z",
     "start_time": "2024-09-27T15:59:45.725497Z"
    }
   },
   "source": [
    "# Load the data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# We need to do this for when we mamke our predictions from the test data at the end\n",
    "ids = test[['PassengerId']]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpMM9RGkam8n"
   },
   "source": [
    "## EDA and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cth9IzJyFMfB"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O33PqcFJ2I0L"
   },
   "source": [
    "You have already performed EDA on this data set. Look back on what you did before or see [here](https://github.com/learn-co-curriculum/enterprise-paired-nn-eval).\n",
    "\n",
    "Of course, feel free to re-run what you have done before or try out some other EDA as you find useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTBTMLo2LmX8"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZm21BwmRwhc"
   },
   "source": [
    "Let's do the same prepricessing as before."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "grIYWsljkf-j",
    "ExecuteTime": {
     "end_time": "2024-09-27T15:59:52.954368Z",
     "start_time": "2024-09-27T15:59:52.907029Z"
    }
   },
   "source": [
    "# Performing preprocessing on the train and test data will be more effecient if we combine the two date sets.\n",
    "combined = pd.concat([train, test], axis=0, sort=False)\n",
    "\n",
    "#Age column\n",
    "combined['Age'].fillna(combined['Age'].median(),inplace=True) # Age\n",
    "\n",
    "# Embarked column\n",
    "combined['Embarked'].fillna(combined['Embarked'].value_counts().index[0], inplace=True) # Embarked\n",
    "combined['Fare'].fillna(combined['Fare'].median(),inplace=True)\n",
    "\n",
    "# Class column\n",
    "d = {1:'1st',2:'2nd',3:'3rd'} #Pclass\n",
    "combined['Pclass'] = combined['Pclass'].map(d) #Pclass\n",
    "\n",
    "# Making Age into adult (1) and child (0)\n",
    "combined['Child'] = combined['Age'].apply(lambda age: 1 if age>=18 else 0) \n",
    "\n",
    "# Break up the string that has the title and names\n",
    "combined['Title'] = combined['Name'].str.split('.').str.get(0)  # output : 'Futrelle, Mrs'\n",
    "combined['Title'] = combined['Title'].str.split(',').str.get(1) # output : 'Mrs '\n",
    "combined['Title'] = combined['Title'].str.strip()               # output : 'Mrs'\n",
    "combined.groupby('Title').count()\n",
    "\n",
    "# Replace the French titles with Enlgish\n",
    "french_titles = ['Don', 'Dona', 'Mme', 'Ms', 'Mra','Mlle']\n",
    "english_titles = ['Mr', 'Mrs','Mrs','Mrs','Mrs','Miss']\n",
    "for i in range(len(french_titles)):\n",
    "    for j in range(len(english_titles)):\n",
    "        if i == j:\n",
    "            combined['Title'] = combined['Title'].str.replace(french_titles[i],english_titles[j])\n",
    "\n",
    "# Seperate the titles into \"major\" and \"others\", the latter would be, e.g., Reverend\n",
    "major_titles = ['Mr','Mrs','Miss','Master']\n",
    "combined['Title'] = combined['Title'].apply(lambda title: title if title in major_titles else 'Others')\n",
    "\n",
    "#Dropping the Irrelevant Columns\n",
    "combined.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Getting Dummy Variables and Dropping the Original Categorical Variables\n",
    "categorical_vars = combined[['Pclass','Sex','Embarked','Title','Child']] # Get Dummies of Categorical Variables\n",
    "dummies = pd.get_dummies(categorical_vars,drop_first=True)\n",
    "combined = combined.drop(['Pclass','Sex','Embarked','Title','Child'],axis=1)\n",
    "combined = pd.concat([combined, dummies],axis=1)\n",
    "\n",
    "# Separating the data back into train and test sets\n",
    "test = combined[combined['Survived'].isnull()].drop(['Survived'],axis=1)\n",
    "train = combined[combined['Survived'].notnull()]\n",
    "\n",
    "# Training\n",
    "X_train = train.drop(['Survived'],axis=1)\n",
    "y_train = train['Survived']\n",
    "\n",
    "# Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "test = sc.fit_transform(test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjacobs\\AppData\\Local\\Temp\\ipykernel_18052\\2479249210.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Age'].fillna(combined['Age'].median(),inplace=True) # Age\n",
      "C:\\Users\\anjacobs\\AppData\\Local\\Temp\\ipykernel_18052\\2479249210.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Embarked'].fillna(combined['Embarked'].value_counts().index[0], inplace=True) # Embarked\n",
      "C:\\Users\\anjacobs\\AppData\\Local\\Temp\\ipykernel_18052\\2479249210.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined['Fare'].fillna(combined['Fare'].median(),inplace=True)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAC11ZbUU2QP"
   },
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXVpYyEheuns"
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d01WQXssfF_9"
   },
   "source": [
    "#### Define the model as a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_UK7p_szRKy"
   },
   "source": [
    "Let's use the data science pipeline for our neural network model.\n",
    "\n",
    "As you are now using regularization to guard against high variance, i.e. overfitting the data, in the definition of the model below include *dropout* and/or *l2* regularization. Also, feel free to experiment with different activation functions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y36TQucVRl6P",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:01:28.249113Z",
     "start_time": "2024-09-27T16:01:28.233116Z"
    }
   },
   "source": [
    "# It will help to define our model in terms of a pipeline\n",
    "def build_classifier(optimizer):\n",
    "    # insert Sequential and layers here\n",
    "    cls = Sequential()\n",
    "    cls.add(Input(shape=(X_train.shape[1],)))\n",
    "    cls.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    cls.add(Dropout(0.2))\n",
    "    cls.add(Dense(8, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    cls.add(Dropout(0.2))\n",
    "    cls.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    cls.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return cls"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEUJgt17fMms"
   },
   "source": [
    "#### Use grid search to find help you tune the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmQOldEBhEox"
   },
   "source": [
    "You can play with optimizers, epochs, and batch sizes. The ones that we're suggesting are not necessarily the best."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WbrOq56AqMKZ",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:01:52.381669Z",
     "start_time": "2024-09-27T16:01:52.257308Z"
    }
   },
   "source": [
    "# Grid Search\n",
    "classifier = KerasClassifier(model = build_classifier(\"adam\"))\n",
    "param_grid = dict(optimizer = ['Adam'],\n",
    "                  epochs=[10, 20, 50],\n",
    "                  batch_size=[16, 25, 32])\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, scoring='accuracy')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_parameters = grid.best_params_\n",
    "best_accuracy = grid.best_score_"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "h5py must be installed in order to save a model.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 7\u001B[0m\n\u001B[0;32m      3\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(optimizer \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdam\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      4\u001B[0m                   epochs\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m50\u001B[39m],\n\u001B[0;32m      5\u001B[0m                   batch_size\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m32\u001B[39m])\n\u001B[0;32m      6\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mclassifier, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m best_parameters \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mbest_params_\n\u001B[0;32m      9\u001B[0m best_accuracy \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mbest_score_\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:930\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    927\u001B[0m cv_orig \u001B[38;5;241m=\u001B[39m check_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv, y, classifier\u001B[38;5;241m=\u001B[39mis_classifier(estimator))\n\u001B[0;32m    928\u001B[0m n_splits \u001B[38;5;241m=\u001B[39m cv_orig\u001B[38;5;241m.\u001B[39mget_n_splits(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39msplitter\u001B[38;5;241m.\u001B[39msplit)\n\u001B[1;32m--> 930\u001B[0m base_estimator \u001B[38;5;241m=\u001B[39m \u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs, pre_dispatch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_dispatch)\n\u001B[0;32m    934\u001B[0m fit_and_score_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m    935\u001B[0m     scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[0;32m    936\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mrouted_params\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mfit,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    943\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[0;32m    944\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:90\u001B[0m, in \u001B[0;36mclone\u001B[1;34m(estimator, safe)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Construct a new unfitted estimator with the same parameters.\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \n\u001B[0;32m     43\u001B[0m \u001B[38;5;124;03mClone does a deep copy of the model in an estimator\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;124;03mFalse\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sklearn_clone__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misclass(estimator):\n\u001B[1;32m---> 90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__sklearn_clone__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _clone_parametrized(estimator, safe\u001B[38;5;241m=\u001B[39msafe)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:296\u001B[0m, in \u001B[0;36mBaseEstimator.__sklearn_clone__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__sklearn_clone__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_clone_parametrized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:123\u001B[0m, in \u001B[0;36m_clone_parametrized\u001B[1;34m(estimator, safe)\u001B[0m\n\u001B[0;32m    121\u001B[0m new_object_params \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mget_params(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m new_object_params\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 123\u001B[0m     new_object_params[name] \u001B[38;5;241m=\u001B[39m \u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    125\u001B[0m new_object \u001B[38;5;241m=\u001B[39m klass(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnew_object_params)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:91\u001B[0m, in \u001B[0;36mclone\u001B[1;34m(estimator, safe)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sklearn_clone__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misclass(estimator):\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m estimator\u001B[38;5;241m.\u001B[39m__sklearn_clone__()\n\u001B[1;32m---> 91\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_clone_parametrized\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:104\u001B[0m, in \u001B[0;36m_clone_parametrized\u001B[1;34m(estimator, safe)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mtype\u001B[39m):\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m safe:\n\u001B[1;32m--> 104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    106\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\copy.py:153\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    151\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\_saving_utils.py:37\u001B[0m, in \u001B[0;36mdeepcopy_model\u001B[1;34m(model, memo)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeepcopy_model\u001B[39m(model: keras\u001B[38;5;241m.\u001B[39mModel, memo: Dict[Hashable, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel:\n\u001B[1;32m---> 37\u001B[0m     _, (model_bytes,) \u001B[38;5;241m=\u001B[39m \u001B[43mpack_keras_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m     new_model \u001B[38;5;241m=\u001B[39m unpack_keras_model(model_bytes)\n\u001B[0;32m     39\u001B[0m     memo[model] \u001B[38;5;241m=\u001B[39m new_model\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\_saving_utils.py:31\u001B[0m, in \u001B[0;36mpack_keras_model\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     29\u001B[0m     name \u001B[38;5;241m=\u001B[39m tp\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     30\u001B[0m     keras\u001B[38;5;241m.\u001B[39msaving\u001B[38;5;241m.\u001B[39mregister_keras_serializable(module, name)(tp)\n\u001B[1;32m---> 31\u001B[0m \u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m model_bytes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(\u001B[38;5;28mmemoryview\u001B[39m(out\u001B[38;5;241m.\u001B[39mgetvalue()))\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (unpack_keras_model, (model_bytes,))\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:97\u001B[0m, in \u001B[0;36msave_model\u001B[1;34m(model, filepath, weights_format, zipped)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Save a zip-archive representing a Keras model to the given file or path.\u001B[39;00m\n\u001B[0;32m     74\u001B[0m \n\u001B[0;32m     75\u001B[0m \u001B[38;5;124;03mThe zip-based archive contains the following structure:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;124;03mlayer attribute.\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_format \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mh5\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m h5py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mh5py must be installed in order to save a model.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model\u001B[38;5;241m.\u001B[39mbuilt:\n\u001B[0;32m    100\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    101\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are saving a model that has not yet been built. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt might not contain any weights yet. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    105\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    106\u001B[0m     )\n",
      "\u001B[1;31mImportError\u001B[0m: h5py must be installed in order to save a model."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxPY-mYffZLI"
   },
   "source": [
    "#### `TensorBoard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gojep38STZCg"
   },
   "source": [
    "`TensorBoard` is `TensorFlow`'s visualization toolkit. It is a dashboard that provides visualization and tooling that is needed for machine learning experimentation. The code immediately below will allow us to use TensorBoard.\n",
    "\n",
    "N.B. When we loaded the libraries, we loaded the TensorBoard notebook extension. (It is the last line of code in the first code chunk.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rpclz6HWTafA",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:18:21.805954Z",
     "start_time": "2024-09-27T16:18:20.973220Z"
    }
   },
   "source": [
    "# Clear out any prior log data.\n",
    "!rm -rf logs\n",
    "# Be careful not to run this command if already have trained your model and you want to use TensorBoard.\n",
    "\n",
    "# Sets up a timestamped log directory\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "\n",
    "# The callback function, which will be called in the fit()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJR7Qdo3f2zV"
   },
   "source": [
    "#### Fitting the optimal model and evaluating with `TensorBoaard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSvdmzSoeysd"
   },
   "source": [
    "Define the early stopping callback. Use your best values from grid serarch with `KerasClassifer` and finally fit the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "swULa4QCUC83",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:18:48.437955Z",
     "start_time": "2024-09-27T16:18:44.193874Z"
    }
   },
   "source": [
    "# Define the EarlyStopping object\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-8,\n",
    "                           verbose=1, patience=5,\n",
    "                           mode='min')\n",
    "\n",
    "# Using KerasClassifier\n",
    "classifier = KerasClassifier(model = build_classifier(\"adam\"),\n",
    "                             optimizer=\"adam\",\n",
    "                             batch_size=32,\n",
    "                             epochs=50)\n",
    "\n",
    "# Fit the model with the tensorboard_callback\n",
    "classifier.fit(X_train,\n",
    "               y_train,\n",
    "               verbose=1,\n",
    "               callbacks=[early_stop, tensorboard_callback])\n",
    "\n",
    "\n",
    "# Warning: If verbose = 0 (silent) or 2 (one line per epoch), then on TensorBoard's Graphs tab there will be an error.\n",
    "# The other tabs in TensorBoard will still be function, but if you want the graphs then verbose needs to be 1 (progress bar)."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.4104 - loss: 1.2512   \n",
      "Epoch 2/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4678 - loss: 1.1620 \n",
      "Epoch 3/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5045 - loss: 1.0015 \n",
      "Epoch 4/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6088 - loss: 0.9494 \n",
      "Epoch 5/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 894us/step - accuracy: 0.6940 - loss: 0.8625\n",
      "Epoch 6/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6719 - loss: 0.8413 \n",
      "Epoch 7/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7353 - loss: 0.8067 \n",
      "Epoch 8/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7506 - loss: 0.7693 \n",
      "Epoch 9/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7478 - loss: 0.7471 \n",
      "Epoch 10/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7425 - loss: 0.7247 \n",
      "Epoch 11/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7977 - loss: 0.6770 \n",
      "Epoch 12/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.7647 - loss: 0.6755\n",
      "Epoch 13/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7785 - loss: 0.6379 \n",
      "Epoch 14/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7757 - loss: 0.6410 \n",
      "Epoch 15/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7390 - loss: 0.6679\n",
      "Epoch 16/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7528 - loss: 0.6683 \n",
      "Epoch 17/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8300 - loss: 0.5841 \n",
      "Epoch 18/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8031 - loss: 0.6057 \n",
      "Epoch 19/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8004 - loss: 0.5780 \n",
      "Epoch 20/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8159 - loss: 0.5937 \n",
      "Epoch 21/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8057 - loss: 0.5633 \n",
      "Epoch 22/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8050 - loss: 0.5557 \n",
      "Epoch 23/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7837 - loss: 0.5931 \n",
      "Epoch 24/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8200 - loss: 0.5358 \n",
      "Epoch 25/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8411 - loss: 0.5150 \n",
      "Epoch 26/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8319 - loss: 0.5565 \n",
      "Epoch 27/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8186 - loss: 0.5226 \n",
      "Epoch 28/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8138 - loss: 0.5291 \n",
      "Epoch 29/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8343 - loss: 0.5205 \n",
      "Epoch 30/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8096 - loss: 0.5408 \n",
      "Epoch 31/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8380 - loss: 0.5104 \n",
      "Epoch 32/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8216 - loss: 0.5387 \n",
      "Epoch 33/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 572us/step - accuracy: 0.8362 - loss: 0.4967\n",
      "Epoch 34/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8043 - loss: 0.5300 \n",
      "Epoch 35/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8097 - loss: 0.5171 \n",
      "Epoch 36/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8339 - loss: 0.5139 \n",
      "Epoch 37/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8279 - loss: 0.4877 \n",
      "Epoch 38/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8343 - loss: 0.4780 \n",
      "Epoch 39/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.8308 - loss: 0.4880\n",
      "Epoch 40/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8347 - loss: 0.4773 \n",
      "Epoch 41/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8267 - loss: 0.4889 \n",
      "Epoch 42/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8540 - loss: 0.4595 \n",
      "Epoch 43/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - accuracy: 0.8325 - loss: 0.4867\n",
      "Epoch 44/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8169 - loss: 0.5054\n",
      "Epoch 45/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 653us/step - accuracy: 0.8140 - loss: 0.4932\n",
      "Epoch 46/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 581us/step - accuracy: 0.8278 - loss: 0.4908\n",
      "Epoch 47/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 556us/step - accuracy: 0.8115 - loss: 0.5124\n",
      "Epoch 48/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 642us/step - accuracy: 0.8279 - loss: 0.4827\n",
      "Epoch 49/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8281 - loss: 0.4767 \n",
      "Epoch 50/50\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8247 - loss: 0.4882 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<Sequential name=sequential_2, built=True>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=adam\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;Sequential name=sequential_2, built=True&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=adam\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KerasClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;Sequential name=sequential_2, built=True&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=adam\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       "\tclass_weight=None\n",
       ")</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r-yFJ3l6AIiw",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:18:50.297955Z",
     "start_time": "2024-09-27T16:18:50.266459Z"
    }
   },
   "source": [
    "# Call TensorBoard within SaturnCloud [Comment this out if you are not in SaturnCloud]\n",
    "import os\n",
    "print(f\"https://{os.getenv('SATURN_JUPYTER_BASE_DOMAIN')}/proxy/8000/\")\n",
    "%tensorboard --logdir logs/fit --port 8000 --bind_all\n",
    "# This will generate a hyperlink. Click on that to open TensorBoard!\n",
    "# (You'll see a 404 error below the link, just ignore that.)\n",
    "\n",
    "# Call TensorBoard [Not in SaturnCloud]\n",
    "# Uncomment the next time if you are not in SC\n",
    "# %tensorboard --logdir logs/fit"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://None/proxy/8000/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8000 (pid 6828), started 1 day, 21:25:40 ago. (Use '!kill 6828' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-789f95a1be0fe726\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-789f95a1be0fe726\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8000;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx3aSuzagU35"
   },
   "source": [
    "#### Results and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_ab2ezifD6k"
   },
   "source": [
    "Calculate the predictions, save them as a csv, and print them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-wEYDe-CzeVG",
    "ExecuteTime": {
     "end_time": "2024-09-27T16:18:52.983269Z",
     "start_time": "2024-09-27T16:18:52.866639Z"
    }
   },
   "source": [
    "# Your code here (use more cells if you need to)\n",
    "pd.DataFrame(classifier.predict(test)).to_csv('predictions.csv')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xd1lF1f9T4w"
   },
   "source": [
    "Continue to tweak your model until you are happy with the results based on model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T1ej4W68j-T"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHW7vUl19I9R"
   },
   "source": [
    "Now that you have the `TensorBoard` to help you look at your model, you can better understand how to tweak your model.\n",
    "\n",
    "How do your predictions compare to what you did last time?\n",
    "\n",
    "Remember that your \"fancier\" model may be less accurate... but that is okay if that is the case since we're trying to guard against variance with regularization techniques."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
